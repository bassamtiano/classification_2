{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "# !gdown --folder https://drive.google.com/drive/folders/1ZRJ3Z16RuOYD8tanp27aqOC53fCftG_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liputan6.com, London - Lee Dixon khawatir Arse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liputan6.com, Jakarta - Kasus dugaan penganiay...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liputan6.com, Jakarta Menanggapi aksi eks peke...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liputan6.com, Medan - Sebanyak 81 kendaraan 4x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liputan6.com, Jakarta Indonesia akan melawan T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>Liputan6.com, Jakarta Badan Pusat Statistik (B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>Liputan6.com, Jakarta - PT Waskita Beton Preca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>Liputan6SCTV, Bengkalis - Panglima TNI Marseka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>Liputan6.com, Jakarta - Tahapan wawancara kerj...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>Jakarta - Timnas Indonesia U-22 bersua Vietnam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6127 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  label\n",
       "0     Liputan6.com, London - Lee Dixon khawatir Arse...      0\n",
       "1     Liputan6.com, Jakarta - Kasus dugaan penganiay...      1\n",
       "2     Liputan6.com, Jakarta Menanggapi aksi eks peke...      2\n",
       "3     Liputan6.com, Medan - Sebanyak 81 kendaraan 4x...      0\n",
       "4     Liputan6.com, Jakarta Indonesia akan melawan T...      0\n",
       "...                                                 ...    ...\n",
       "6122  Liputan6.com, Jakarta Badan Pusat Statistik (B...      2\n",
       "6123  Liputan6.com, Jakarta - PT Waskita Beton Preca...      2\n",
       "6124  Liputan6SCTV, Bengkalis - Panglima TNI Marseka...      1\n",
       "6125  Liputan6.com, Jakarta - Tahapan wawancara kerj...      2\n",
       "6126  Jakarta - Timnas Indonesia U-22 bersua Vietnam...      0\n",
       "\n",
       "[6127 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {\n",
    "    'bola': 0,\n",
    "    'news': 1,\n",
    "    'bisnis': 2,\n",
    "    'tekno': 3,\n",
    "    'otomotif': 4\n",
    "}\n",
    "\n",
    "# def perhitungan(nilai):\n",
    "#   return nilai * 2\n",
    "\n",
    "def load_data():\n",
    "  with open(\"dataset/training.res\", \"rb\") as tdr:\n",
    "    train_pkl = pickle.load(tdr)\n",
    "    train = pd.DataFrame({'title': train_pkl[0], 'label': train_pkl[1]})\n",
    "  \n",
    "  with open(\"dataset/testing.res\", \"rb\") as tsdr:\n",
    "    test_pkl = pickle.load(tsdr)\n",
    "    test = pd.DataFrame({'title': test_pkl[0], 'label': test_pkl[1]})\n",
    "  \n",
    "  train.label = train.label.map(label2id)\n",
    "  test[\"label\"] = test.label.map(label2id)\n",
    "\n",
    "  # train[\"hitung\"] = train['label'].apply(lambda x: perhitungan(x))\n",
    "\n",
    "  return train, test\n",
    "\n",
    "train, test = load_data()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Sastrawi\n",
    "\n",
    "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# factory = StemmerFactory()\n",
    "# stemmer = factory.create_stemmer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membersihkan String dari Karakter yang tidak diinginkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def clean_str(string):\n",
    "#     string = string.lower()\n",
    "#     string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\-`]\", \" \", string)\n",
    "#     # sebelum = hari ini mendung? | setelah = hari ini mendung ?\n",
    "#     string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "#     string = re.sub(r\"\\!\", \" \\! \", string)\n",
    "    \n",
    "#     # sebelum = ayam,nasi,sambel | setelah ayam , nasi , sambel\n",
    "#     string = re.sub(r\",\", \" , \", string)\n",
    "    \n",
    "#     # menghilangkan whitespace / spasi berlebih\n",
    "#     string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    \n",
    "#     # menghapus \\n / next line\n",
    "#     string = re.sub(r\"\\n\", \"\", string)\n",
    "    \n",
    "#     # menghapus \\n\\t / next line + tab\n",
    "#     string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    \n",
    "#     string = string.strip()\n",
    "    \n",
    "#     return stemmer.stem(string)\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "Merubah kata menjadi ID menggunakan pre-trained model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# # Progress Bar\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from torch.utils.data import TensorDataset\n",
    "\n",
    "# import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('indolem/indobert-base-uncased')\n",
    "\n",
    "# max_sentence_length = 100\n",
    "\n",
    "# def arange_data(data, type):\n",
    "#     x_input_ids, y = [], []\n",
    "    \n",
    "#     for i_baris, kalimat in enumerate(tqdm(data.values.tolist())):\n",
    "#         judul = clean_str(kalimat[0])\n",
    "#         label = kalimat[1]\n",
    "        \n",
    "#         judul_ids = tokenizer(\n",
    "#             text = judul,\n",
    "#             max_length = max_sentence_length,\n",
    "#             padding = 'max_length',\n",
    "#             truncation = True\n",
    "#         )[\"input_ids\"]\n",
    "        \n",
    "#         y_label = [0] * len(label2id)\n",
    "#         y_label[int(label)] = 1\n",
    "\n",
    "#         x_input_ids.append(judul_ids)\n",
    "#         y.append(y_label)\n",
    "        \n",
    "#         # if i_baris > 10:\n",
    "#         #     break\n",
    "    \n",
    "#     # List to tensor\n",
    "#     x_input_ids = torch.tensor(x_input_ids)\n",
    "#     y = torch.tensor(y)\n",
    "    \n",
    "#     tensor_dataset = TensorDataset(x_input_ids, y)\n",
    "    \n",
    "#     # Fine Tunning(Training, Validation), Testing\n",
    "#     # Fine tunning(Training ratio = 0.8, Validation = 0.2)\n",
    "    \n",
    "#     if type == \"train\":\n",
    "#         # Pemisahana data untuk training\n",
    "#         train_tensor_dataset, valid_tensor_dataset = torch.utils.data.random_split(tensor_dataset, [\n",
    "#                                                                               round(len(x_input_ids) * 0.8), \n",
    "#                                                                               len(x_input_ids) - round(len(x_input_ids) * 0.8)])\n",
    "#         torch.save(train_tensor_dataset, \"preprocessed/train.pt\")\n",
    "#         torch.save(valid_tensor_dataset, \"preprocessed/valid.pt\")\n",
    "        \n",
    "#         return train_tensor_dataset, valid_tensor_dataset\n",
    "    \n",
    "#     else:\n",
    "#         torch.save(tensor_dataset, \"preprocessed/test.pt\")\n",
    "#         return tensor_dataset\n",
    "        \n",
    "\n",
    "# train_dataset, validation_dataset = arange_data(data = train, type = \"train\")\n",
    "# test_dataset = arange_data(data = test, type = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bassamtiano/anaconda3/envs/text/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-02 04:29:03.897471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-02 04:29:04.042175: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-02 04:29:04.545428: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2023-04-02 04:29:04.546697: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2023-04-02 04:29:04.546704: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Preprocessed Data\n",
    "train_dataset = torch.load(\"dataset/preprocessed/train.pt\")\n",
    "validation_dataset = torch.load(\"dataset/preprocessed/valid.pt\")\n",
    "test_dataset = torch.load(\"dataset/preprocessed/test.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fb0808a3d00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "def preprocessor(train_datasets, validation_datasets, test_datasets):\n",
    "    train_datasets = DataLoader(\n",
    "        dataset = train_datasets,\n",
    "        batch_size = batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers = 4\n",
    "    )\n",
    "    \n",
    "    validation_datasets = DataLoader(\n",
    "        dataset = validation_datasets,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = 4\n",
    "    )\n",
    "    \n",
    "    test_datasets = DataLoader(\n",
    "        dataset = test_datasets,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = 4 \n",
    "    )\n",
    "    \n",
    "    return train_datasets, validation_datasets, test_datasets\n",
    "\n",
    "train_datasets, validation_datasets, test_datasets = preprocessor(train_dataset, validation_dataset, test_dataset)\n",
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    train_dataset = torch.load(\"dataset/preprocessed/train.pt\")\n",
    "    validation_dataset = torch.load(\"dataset/preprocessed/valid.pt\")\n",
    "    test_dataset = torch.load(\"dataset/preprocessed/test.pt\")\n",
    "\n",
    "    return train_datasets, validation_datasets, test_datasets  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mulai Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7faf79e99f30>\n",
      "Epoch =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4902 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    3, 21666,  2589, 14135,    17,  4208, 18495,  3304, 11938,  2021,\n",
      "         2842,  9180,  9562,  3868,  1485,  3304, 11938, 14135, 17386,  3911,\n",
      "         2021,  2359,  1814,  2715,  1994,  1545,  4484,  5812, 16875,   934,\n",
      "        11758,    21,  5167,  1500,  7964,  2832, 12964,  1535,  1730, 10791,\n",
      "        21666,  3041,  3601,  2157,    22,  7063,  2082,  5729,  1559,  2261,\n",
      "         6739,  1501,  1580, 10970,  1686,  2706,  1540,  2077, 12215,  7340,\n",
      "         2082,  2103,  1570, 18148, 26368,  1485,  1558, 14732, 20354, 11938,\n",
      "         1855,  5646,  2390,  1853,  4875,  1991,  1798,  2842,  4719, 21661,\n",
      "         1575,  1534,  1476,  1730,  8587, 16586, 17281, 12394,  2129,  2668,\n",
      "         7537,  1802,  1485,  2269,  3197,  3588,  2034,  7261,  2856,     4],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bassamtiano/anaconda3/envs/text/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from utils.multi_class_trainer import MultiClassTrainer\n",
    "\n",
    "mclass_trainer = MultiClassTrainer(dropout = 0.1, \n",
    "                                   lr = 2e-5,\n",
    "                                   max_epoch = 10,\n",
    "                                   device = \"cuda\",\n",
    "                                   n_class= len(label2id))\n",
    "mclass_trainer.trainer(train_dataset, validation_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_dataset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a897da0134c4af538d8145dc3818d8156ca8f66c244eb9debe26b9ca43b0cc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
